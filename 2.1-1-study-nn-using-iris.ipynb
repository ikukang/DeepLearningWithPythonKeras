{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 상의 편의를 위한 Initial Setting\n",
    "\n",
    "# 실행결과를 한 창에 표시\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# numpy 소숫점 setting\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=7)\n",
    "\n",
    "# pandas이용하여 grid display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)         # 최대 표시 줄 수 제한 해제\n",
    "pd.set_option('display.max_columns', None)  # 최대 표시 컬럼 수 제한 해제\n",
    "pd.set_option('display.max_colwidth', -1)        # 컬럼내 데이터 표시 제한 해제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Iris 품종 (Versicolor, Virginica, Setosa)\n",
    "![iris(1)](https://user-images.githubusercontent.com/38086434/67282294-6423ef00-f50c-11e9-945d-42ce959a0cce.jpg)\n",
    "\n",
    " ### Iris Petal(꽃잎) width / length 에 따른 Categorize\n",
    "![iris(2)](https://user-images.githubusercontent.com/38086434/67282497-e0b6cd80-f50c-11e9-97a3-0402ab5f1ecc.jpg)\n",
    "\n",
    " #### 출처 : http://articles.concreteinteractive.com/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image\n",
    "# Image(\"./image/iris(1).jpg\")\n",
    "# Image(\"./image/iris(2).jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런의  load_iris method를 import 하여 iris data, label을 얻음\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_label = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런 의  train_test_split method를 import 하여 train_data : test_data = 6:4 의 비율로 split 함\n",
    "from sklearn.model_selection import train_test_split\n",
    "(train_data, test_data, train_label, test_label) = train_test_split(iris_data, iris_label, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(90, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(90,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 iris data의 shape을 확인 (150건의 row가 존재하고, 각 row에는  다음과 같이 붓꽃의 꽃잎과 꽃받침의  length, width 임\n",
    "# iris_data shape : (150 , 4)      --> 전체 150 건의 Data,  [‘sepal length (cm)’, ‘sepal width (cm)’, ‘petal length (cm)’, ‘petal width (cm)’] 로 구성\n",
    "# train_data shape : (90 , 4)     --> 전체의 60%인 90 row의 Data, [‘sepal length (cm)’, ‘sepal width (cm)’, ‘petal length (cm)’, ‘petal width (cm)’] 로 구성\n",
    "# test_data shape : (60 , 4)       --> 전체의 40%인 60 row의 Data, [‘sepal length (cm)’, ‘sepal width (cm)’, ‘petal length (cm)’, ‘petal width (cm)’] 로 구성\n",
    "# train_label shape : (90,)         --> 전체의 60%인 90 row의 Data, 각 Data는 0, 1, 2 중 하나로 구성 (0:Setosa, 1:Versicolor, 2:Virginica)\n",
    "# test_label shape : (60,)           --> 전체의 40%인 60 row의 Data, 각 Data는 0, 1, 2 중 하나로 구성 (0:Setosa, 1:Versicolor, 2:Virginica)\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#  Train/Test Data : [‘sepal length (cm)’, ‘sepal width (cm)’, ‘petal length (cm)’, ‘petal width (cm)’]    * sepal: 꽃받침 / petal: 꽃잎\n",
    "#  Train/Test Label :   0: Setosa\n",
    "#                                   1: Versicolor\n",
    "#                                   2: Virginica\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "iris_data.shape\n",
    "train_data.shape\n",
    "test_data.shape\n",
    "train_label.shape\n",
    "test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Network에 주입하기 위해 train_label, test_label을 one-hot-encoding 형식으로 변환\n",
    "from keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_label)\n",
    "test_labels = to_categorical(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras를 import 하고, 계층을 선형적으로 쌓는 sequential 모델을 사용\n",
    "# add method를 이용하여 쉽게 layer를 쌓을 수 있음\n",
    "# 활성화 함수는 relu를 사용하고, input shape는 4개의 iris sepal/petal의 length/width 임 \n",
    "# 즉, [‘sepal length (cm)’, ‘sepal width (cm)’, ‘petal length (cm)’, ‘petal width (cm)’]    * sepal: 꽃받침 / petal: 꽃잎)\n",
    "# 출력함수로 softmax 함수를 이용, 4개의 입력 값을 0~1 사이의 값으로 정규화 하고, argmax method를 이용하여 one-hot encoding\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(64, activation='relu', input_shape=(4,)))\n",
    "# 입력층 : 입력 parameter는 4이고, 출력 parameter는 64 임, 활성화 함수는 relu\n",
    "# 즉 [‘sepal length (cm)’, ‘sepal width (cm)’, ‘petal length (cm)’, ‘petal width (cm)’]\n",
    "\n",
    "network.add(layers.Dense(64, activation='relu'))\n",
    "# 은닉층 : 입력 parameter는 64(이전 layer의 출력)이고, 출력 parameter는 64 임, 활성화 함수는 relu\n",
    "\n",
    "network.add(layers.Dense(3, activation='softmax'))\n",
    "# 출력층 : 입력 parameter는 64(이전 layer의 출력) 이고, 출력 parameter는 3임, 활성화 함수는 softmax\n",
    "# 즉  0: Setosa, 1: Versicolor, 2: Virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                320       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 4,675\n",
      "Trainable params: 4,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network.summary()\n",
    "\n",
    "#  dense_1 layer의 전체 paramenter의 수는 64 * 4 + 64 = 320 임 (추가적으로 더하는 64는 bias)\n",
    "#  dense_2 layer의 전체 paramenter의 수는 64 * 64 + 64 = 4,160 임 (추가적으로 더하는 64은 bias)\n",
    "#  dense_3 layer의 전체 paramenter의 수는 64 * 3 + 3 = 195 임 (추가적으로 더하는 3은 bias)\n",
    "# 그러므로 총 paramter의 수는 320 + 4,160 + 195 = 4,675"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile method를 이용하여 학습 과정을 구성\n",
    "# 옵티마이저는 Adam을사용하고, 손실함수는 교차 엔트로피 오차(Cross Entropy Error) 함수를 이용\n",
    "\n",
    "network.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/40\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 1.3986 - accuracy: 0.3667\n",
      "Epoch 2/40\n",
      "90/90 [==============================] - 0s 65us/step - loss: 1.1767 - accuracy: 0.5889\n",
      "Epoch 3/40\n",
      "90/90 [==============================] - 0s 44us/step - loss: 1.0005 - accuracy: 0.6444\n",
      "Epoch 4/40\n",
      "90/90 [==============================] - 0s 48us/step - loss: 0.8822 - accuracy: 0.7222\n",
      "Epoch 5/40\n",
      "90/90 [==============================] - 0s 50us/step - loss: 0.8229 - accuracy: 0.7000\n",
      "Epoch 6/40\n",
      "90/90 [==============================] - 0s 49us/step - loss: 0.7933 - accuracy: 0.7000\n",
      "Epoch 7/40\n",
      "90/90 [==============================] - 0s 52us/step - loss: 0.7649 - accuracy: 0.7000\n",
      "Epoch 8/40\n",
      "90/90 [==============================] - 0s 46us/step - loss: 0.7326 - accuracy: 0.7000\n",
      "Epoch 9/40\n",
      "90/90 [==============================] - 0s 47us/step - loss: 0.6907 - accuracy: 0.7000\n",
      "Epoch 10/40\n",
      "90/90 [==============================] - 0s 51us/step - loss: 0.6577 - accuracy: 0.7000\n",
      "Epoch 11/40\n",
      "90/90 [==============================] - 0s 52us/step - loss: 0.6287 - accuracy: 0.7000\n",
      "Epoch 12/40\n",
      "90/90 [==============================] - 0s 48us/step - loss: 0.6023 - accuracy: 0.7000\n",
      "Epoch 13/40\n",
      "90/90 [==============================] - 0s 46us/step - loss: 0.5782 - accuracy: 0.7000\n",
      "Epoch 14/40\n",
      "90/90 [==============================] - 0s 51us/step - loss: 0.5546 - accuracy: 0.7000\n",
      "Epoch 15/40\n",
      "90/90 [==============================] - 0s 47us/step - loss: 0.5337 - accuracy: 0.7000\n",
      "Epoch 16/40\n",
      "90/90 [==============================] - 0s 44us/step - loss: 0.5145 - accuracy: 0.7000\n",
      "Epoch 17/40\n",
      "90/90 [==============================] - 0s 48us/step - loss: 0.4975 - accuracy: 0.7000\n",
      "Epoch 18/40\n",
      "90/90 [==============================] - 0s 51us/step - loss: 0.4796 - accuracy: 0.7333\n",
      "Epoch 19/40\n",
      "90/90 [==============================] - 0s 47us/step - loss: 0.4653 - accuracy: 0.7667\n",
      "Epoch 20/40\n",
      "90/90 [==============================] - 0s 50us/step - loss: 0.4531 - accuracy: 0.7889\n",
      "Epoch 21/40\n",
      "90/90 [==============================] - 0s 51us/step - loss: 0.4410 - accuracy: 0.8333\n",
      "Epoch 22/40\n",
      "90/90 [==============================] - 0s 49us/step - loss: 0.4295 - accuracy: 0.8444\n",
      "Epoch 23/40\n",
      "90/90 [==============================] - 0s 46us/step - loss: 0.4189 - accuracy: 0.8556\n",
      "Epoch 24/40\n",
      "90/90 [==============================] - 0s 44us/step - loss: 0.4091 - accuracy: 0.8667\n",
      "Epoch 25/40\n",
      "90/90 [==============================] - 0s 45us/step - loss: 0.3993 - accuracy: 0.8778\n",
      "Epoch 26/40\n",
      "90/90 [==============================] - 0s 47us/step - loss: 0.3895 - accuracy: 0.9000\n",
      "Epoch 27/40\n",
      "90/90 [==============================] - 0s 52us/step - loss: 0.3815 - accuracy: 0.8778\n",
      "Epoch 28/40\n",
      "90/90 [==============================] - 0s 44us/step - loss: 0.3723 - accuracy: 0.8778\n",
      "Epoch 29/40\n",
      "90/90 [==============================] - 0s 45us/step - loss: 0.3621 - accuracy: 0.9111\n",
      "Epoch 30/40\n",
      "90/90 [==============================] - 0s 44us/step - loss: 0.3553 - accuracy: 0.9111\n",
      "Epoch 31/40\n",
      "90/90 [==============================] - 0s 48us/step - loss: 0.3449 - accuracy: 0.9333\n",
      "Epoch 32/40\n",
      "90/90 [==============================] - 0s 49us/step - loss: 0.3362 - accuracy: 0.9667\n",
      "Epoch 33/40\n",
      "90/90 [==============================] - 0s 44us/step - loss: 0.3289 - accuracy: 0.9556\n",
      "Epoch 34/40\n",
      "90/90 [==============================] - 0s 46us/step - loss: 0.3226 - accuracy: 0.9444\n",
      "Epoch 35/40\n",
      "90/90 [==============================] - 0s 47us/step - loss: 0.3177 - accuracy: 0.9556\n",
      "Epoch 36/40\n",
      "90/90 [==============================] - 0s 51us/step - loss: 0.3042 - accuracy: 0.9333\n",
      "Epoch 37/40\n",
      "90/90 [==============================] - 0s 55us/step - loss: 0.2958 - accuracy: 0.9667\n",
      "Epoch 38/40\n",
      "90/90 [==============================] - 0s 51us/step - loss: 0.2884 - accuracy: 0.9889\n",
      "Epoch 39/40\n",
      "90/90 [==============================] - 0s 52us/step - loss: 0.2820 - accuracy: 0.9889\n",
      "Epoch 40/40\n",
      "90/90 [==============================] - 0s 53us/step - loss: 0.2735 - accuracy: 0.9889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f74e41bc3c8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit method를 이용해서 정해진 epoch 만큼  Training을 수행\n",
    "# 이때 위에서 재 정의한 train_data, train_label을 주입하고, epoch를 지정\n",
    "\n",
    "network.fit(train_data, train_labels, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 395us/step\n"
     ]
    }
   ],
   "source": [
    "# evaluate method를 이용하여 입력 test data에 대한 loss, accuracy를 계산\n",
    "test_loss, test_acc = network.evaluate(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc :  0.949999988079071\n",
      "test_loss :  0.31725478172302246\n"
     ]
    }
   ],
   "source": [
    "print('test_acc : ', test_acc)\n",
    "print('test_loss : ', test_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
