{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 상의 편의를 위한 Initial Setting\n",
    "\n",
    "# 실행결과를 한 창에 표시\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# numpy 소숫점 setting\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=7)\n",
    "\n",
    "# pandas이용하여 grid display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)         # 최대 표시 줄 수 제한 해제\n",
    "pd.set_option('display.max_columns', None)  # 최대 표시 컬럼 수 제한 해제\n",
    "pd.set_option('display.max_colwidth', -1)        # 컬럼내 데이터 표시 제한 해제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris 품종 (Versicolor, Virginica, Setosa)\n",
    "![title](./image/iris(1).jpg)\n",
    "\n",
    "### Iris Petal(꽃잎) width / length 에 따른 Categorize\n",
    "![title](./image/iris(2).jpg)\n",
    "\n",
    "#### 출처 : http://articles.concreteinteractive.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image\n",
    "# Image(\"./image/iris(1).jpg\")\n",
    "# Image(\"./image/iris(2).jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런의  load_iris method를 import 하여 iris data, label을 얻음\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_label = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런 의  train_test_split method를 import 하여 train_data : test_data = 6:4 의 비율로 split 함\n",
    "from sklearn.model_selection import train_test_split\n",
    "(train_data, test_data, train_label, test_label) = train_test_split(iris_data, iris_label, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(90, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(90,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 iris data의 shape을 확인 (150건의 row가 존재하고, 각 row에는  다음과 같이 붓꽃의 꽃잎과 꽃받침의  length, width 임\n",
    "# iris_data shape : (150 , 4)      --> 전체 150 건의 Data,  [‘sepal length (cm)’, ‘sepal width (cm)’, ‘petal length (cm)’, ‘petal width (cm)’] 로 구성\n",
    "# train_data shape : (90 , 4)     --> 전체의 60%인 90 row의 Data, [‘sepal length (cm)’, ‘sepal width (cm)’, ‘petal length (cm)’, ‘petal width (cm)’] 로 구성\n",
    "# test_data shape : (60 , 4)       --> 전체의 40%인 60 row의 Data, [‘sepal length (cm)’, ‘sepal width (cm)’, ‘petal length (cm)’, ‘petal width (cm)’] 로 구성\n",
    "# train_label shape : (90,)         --> 전체의 60%인 90 row의 Data, 각 Data는 0, 1, 2 중 하나로 구성 (0:Setosa, 1:Versicolor, 2:Virginica)\n",
    "# test_label shape : (60,)           --> 전체의 40%인 60 row의 Data, 각 Data는 0, 1, 2 중 하나로 구성 (0:Setosa, 1:Versicolor, 2:Virginica)\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#  Train/Test Data : [‘sepal length (cm)’, ‘sepal width (cm)’, ‘petal length (cm)’, ‘petal width (cm)’]    * sepal: 꽃받침 / petal: 꽃잎\n",
    "#  Train/Test Label :   0: Setosa\n",
    "#                                   1: Versicolor\n",
    "#                                   2: Virginica\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "iris_data.shape\n",
    "train_data.shape\n",
    "test_data.shape\n",
    "train_label.shape\n",
    "test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network에 주입하기 위해 train_label, test_label을 one-hot-encoding 형식으로 변환\n",
    "from keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_label)\n",
    "test_labels = to_categorical(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras를 import 하고, 계층을 선형적으로 쌓는 sequential 모델을 사용\n",
    "# add method를 이용하여 쉽게 layer를 쌓을 수 있음\n",
    "# 활성화 함수는 relu를 사용하고, input shape는 4개의 iris sepal/petal의 length/width 임 \n",
    "# 즉, [‘sepal length (cm)’, ‘sepal width (cm)’, ‘petal length (cm)’, ‘petal width (cm)’]    * sepal: 꽃받침 / petal: 꽃잎)\n",
    "# 출력함수로 softmax 함수를 이용, 4개의 입력 값을 0~1 사이의 값으로 정규화 하고, argmax method를 이용하여 one-hot encoding\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(64, activation='relu', input_shape=(4,)))\n",
    "# 입력층 : 입력 parameter는 4이고, 출력 parameter는 64 임, 활성화 함수는 relu\n",
    "# 즉 [‘sepal length (cm)’, ‘sepal width (cm)’, ‘petal length (cm)’, ‘petal width (cm)’]\n",
    "\n",
    "network.add(layers.Dense(64, activation='relu'))\n",
    "# 은닉층 : 입력 parameter는 64(이전 layer의 출력)이고, 출력 parameter는 64 임, 활성화 함수는 relu\n",
    "\n",
    "network.add(layers.Dense(3, activation='softmax'))\n",
    "# 출력층 : 입력 parameter는 64(이전 layer의 출력) 이고, 출력 parameter는 3임, 활성화 함수는 softmax\n",
    "# 즉  0: Setosa, 1: Versicolor, 2: Virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                320       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 4,675\n",
      "Trainable params: 4,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile method를 이용하여 학습 과정을 구성\n",
    "# 옵티마이저는 Adam을사용하고, 손실함수는 교차 엔트로피 오차(Cross Entropy Error) 함수를 이용\n",
    "\n",
    "network.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/40\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 1.4058 - accuracy: 0.3333\n",
      "Epoch 2/40\n",
      "90/90 [==============================] - 0s 53us/step - loss: 1.2301 - accuracy: 0.4333\n",
      "Epoch 3/40\n",
      "90/90 [==============================] - 0s 59us/step - loss: 1.0902 - accuracy: 0.6333\n",
      "Epoch 4/40\n",
      "90/90 [==============================] - 0s 56us/step - loss: 0.9791 - accuracy: 0.6333\n",
      "Epoch 5/40\n",
      "90/90 [==============================] - 0s 48us/step - loss: 0.9096 - accuracy: 0.7222\n",
      "Epoch 6/40\n",
      "90/90 [==============================] - 0s 57us/step - loss: 0.8578 - accuracy: 0.6667\n",
      "Epoch 7/40\n",
      "90/90 [==============================] - 0s 57us/step - loss: 0.8115 - accuracy: 0.6667\n",
      "Epoch 8/40\n",
      "90/90 [==============================] - 0s 47us/step - loss: 0.7700 - accuracy: 0.6667\n",
      "Epoch 9/40\n",
      "90/90 [==============================] - 0s 57us/step - loss: 0.7307 - accuracy: 0.6667\n",
      "Epoch 10/40\n",
      "90/90 [==============================] - 0s 51us/step - loss: 0.6920 - accuracy: 0.6667\n",
      "Epoch 11/40\n",
      "90/90 [==============================] - 0s 50us/step - loss: 0.6585 - accuracy: 0.7333\n",
      "Epoch 12/40\n",
      "90/90 [==============================] - 0s 51us/step - loss: 0.6267 - accuracy: 0.8444\n",
      "Epoch 13/40\n",
      "90/90 [==============================] - 0s 60us/step - loss: 0.5990 - accuracy: 0.8222\n",
      "Epoch 14/40\n",
      "90/90 [==============================] - 0s 61us/step - loss: 0.5722 - accuracy: 0.8111\n",
      "Epoch 15/40\n",
      "90/90 [==============================] - 0s 56us/step - loss: 0.5504 - accuracy: 0.8444\n",
      "Epoch 16/40\n",
      "90/90 [==============================] - 0s 59us/step - loss: 0.5299 - accuracy: 0.8444\n",
      "Epoch 17/40\n",
      "90/90 [==============================] - 0s 59us/step - loss: 0.5117 - accuracy: 0.8222\n",
      "Epoch 18/40\n",
      "90/90 [==============================] - 0s 58us/step - loss: 0.4941 - accuracy: 0.8111\n",
      "Epoch 19/40\n",
      "90/90 [==============================] - 0s 63us/step - loss: 0.4791 - accuracy: 0.8333\n",
      "Epoch 20/40\n",
      "90/90 [==============================] - 0s 61us/step - loss: 0.4631 - accuracy: 0.9000\n",
      "Epoch 21/40\n",
      "90/90 [==============================] - 0s 59us/step - loss: 0.4525 - accuracy: 0.9444\n",
      "Epoch 22/40\n",
      "90/90 [==============================] - 0s 61us/step - loss: 0.4369 - accuracy: 0.9444\n",
      "Epoch 23/40\n",
      "90/90 [==============================] - 0s 61us/step - loss: 0.4254 - accuracy: 0.9444\n",
      "Epoch 24/40\n",
      "90/90 [==============================] - 0s 60us/step - loss: 0.4163 - accuracy: 0.8778\n",
      "Epoch 25/40\n",
      "90/90 [==============================] - 0s 59us/step - loss: 0.4042 - accuracy: 0.8889\n",
      "Epoch 26/40\n",
      "90/90 [==============================] - 0s 50us/step - loss: 0.3931 - accuracy: 0.9444\n",
      "Epoch 27/40\n",
      "90/90 [==============================] - 0s 46us/step - loss: 0.3827 - accuracy: 0.9667\n",
      "Epoch 28/40\n",
      "90/90 [==============================] - 0s 55us/step - loss: 0.3725 - accuracy: 0.9778\n",
      "Epoch 29/40\n",
      "90/90 [==============================] - 0s 50us/step - loss: 0.3637 - accuracy: 0.9667\n",
      "Epoch 30/40\n",
      "90/90 [==============================] - 0s 54us/step - loss: 0.3533 - accuracy: 0.9667\n",
      "Epoch 31/40\n",
      "90/90 [==============================] - 0s 58us/step - loss: 0.3431 - accuracy: 0.9778\n",
      "Epoch 32/40\n",
      "90/90 [==============================] - 0s 80us/step - loss: 0.3333 - accuracy: 0.9778\n",
      "Epoch 33/40\n",
      "90/90 [==============================] - 0s 65us/step - loss: 0.3241 - accuracy: 0.9667\n",
      "Epoch 34/40\n",
      "90/90 [==============================] - 0s 51us/step - loss: 0.3141 - accuracy: 0.9778\n",
      "Epoch 35/40\n",
      "90/90 [==============================] - 0s 57us/step - loss: 0.3054 - accuracy: 0.9778\n",
      "Epoch 36/40\n",
      "90/90 [==============================] - 0s 47us/step - loss: 0.2959 - accuracy: 0.9778\n",
      "Epoch 37/40\n",
      "90/90 [==============================] - 0s 57us/step - loss: 0.2864 - accuracy: 0.9778\n",
      "Epoch 38/40\n",
      "90/90 [==============================] - 0s 60us/step - loss: 0.2779 - accuracy: 0.9778\n",
      "Epoch 39/40\n",
      "90/90 [==============================] - 0s 63us/step - loss: 0.2697 - accuracy: 0.9778\n",
      "Epoch 40/40\n",
      "90/90 [==============================] - 0s 43us/step - loss: 0.2636 - accuracy: 0.9778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f41a9902fd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit method를 이용해서 정해진 epoch 만큼  Training을 수행\n",
    "# 이때 위에서 재 정의한 train_data, train_label을 주입하고, epoch를 지정\n",
    "\n",
    "network.fit(train_data, train_labels, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 397us/step\n"
     ]
    }
   ],
   "source": [
    "# evaluate method를 이용하여 입력 test data에 대한 loss, accuracy를 계산\n",
    "test_loss, test_acc = network.evaluate(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc :  0.9666666388511658\n",
      "test_loss :  0.23805705606937408\n"
     ]
    }
   ],
   "source": [
    "print('test_acc : ', test_acc)\n",
    "print('test_loss : ', test_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
