{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴스 기사 분류: 다중 분류 문제\n",
    "\n",
    "이 노트북은 [케라스 창시자에게 배우는 딥러닝](https://tensorflow.blog/케라스-창시자에게-배우는-딥러닝/) 책의 3장 5절의 코드 예제입니다. 책에는 더 많은 내용과 그림이 있습니다. 이 노트북에는 소스 코드에 관련된 설명만 포함합니다. 이 노트북의 설명은 케라스 버전 2.2.2에 맞추어져 있습니다. 케라스 최신 버전이 릴리스되면 노트북을 다시 테스트하기 때문에 설명과 코드의 결과가 조금 다를 수 있습니다.\n",
    "\n",
    "----\n",
    "\n",
    "이전 섹션에서 완전 연결된 신경망을 사용해 벡터 입력을 어떻게 두 개의 클래스로 분류하는지 보았습니다. 두 개 이상의 클래스가 있을 때는 어떻게 해야 할까요?\n",
    "\n",
    "이 절에서 로이터 뉴스를 46개의 상호 배타적인 토픽으로 분류하는 신경망을 만들어 보겠습니다. 클래스가 많기 때문에 이 문제는 다중 분류의 예입니다. 각 데이터 포인트가 정확히 하나의 범주로 분류되기 때문에 좀 더 정확히 말하면 단일 레이블 다중 분류 문제입니다. 각 데이터 포인트가 여러 개의 범주(가령, 토픽)에 속할 수 있다면 이런 문제는 다중 레이블 다중 분류의 문제가 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로이터 데이터셋\n",
    "\n",
    "1986년에 로이터에서 공개한 짧은 뉴스 기사와 토픽의 집합인 로이터 데이터셋을 사용하겠습니다. 이 데이터셋은 텍스트 분류를 위해 널리 사용되는 간단한 데이터셋입니다. 46개의 토픽이 있으며 어떤 토픽은 다른 것에 비해 데이터가 많습니다. 각 토픽은 훈련 세트에 최소한 10개의 샘플을 가지고 있습니다.\n",
    "\n",
    "IMDB와 MNIST와 마찬가지로 로이터 데이터셋은 케라스에 포함되어 있습니다. 한 번 살펴보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB 데이터셋에서처럼 num_words=10000 매개변수는 데이터에서 가장 자주 등장하는 단어 10,000개로 제한합니다.\n",
    "\n",
    "여기에는 8,982개의 훈련 샘플과 2,246개의 테스트 샘플이 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8982"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2246"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB 리뷰처럼 각 샘플은 정수 리스트입니다(단어 인덱스):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 245,\n",
       " 273,\n",
       " 207,\n",
       " 156,\n",
       " 53,\n",
       " 74,\n",
       " 160,\n",
       " 26,\n",
       " 14,\n",
       " 46,\n",
       " 296,\n",
       " 26,\n",
       " 39,\n",
       " 74,\n",
       " 2979,\n",
       " 3554,\n",
       " 14,\n",
       " 46,\n",
       " 4689,\n",
       " 4329,\n",
       " 86,\n",
       " 61,\n",
       " 3499,\n",
       " 4795,\n",
       " 14,\n",
       " 61,\n",
       " 451,\n",
       " 4329,\n",
       " 17,\n",
       " 12]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "궁금한 경우를 위해 어떻게 단어로 디코딩하는지 알아보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "# 0, 1, 2는 '패딩', '문서 시작', '사전에 없음'을 위한 인덱스이므로 3을 뺍니다\n",
    "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_newswire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "샘플에 연결된 레이블은 토픽의 인덱스로 0과 45 사이의 정수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비\n",
    "\n",
    "이전의 예제와 동일한 코드를 사용해서 데이터를 벡터로 변환합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "# 훈련 데이터 벡터 변환\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# 테스트 데이터 벡터 변환\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블을 벡터로 바꾸는 방법은 두 가지입니다. 레이블의 리스트를 정수 텐서로 변환하는 것과 원-핫 인코딩을 사용하는 것입니다. 원-핫 인코딩이 범주형 데이터에 널리 사용되기 때문에 범주형 인코딩이라고도 부릅니다. 원-핫 인코딩에 대한 자세한 설명은 6.1절을 참고하세요. 이 경우 레이블의 원-핫 인코딩은 각 레이블의 인덱스 자리는 1이고 나머지는 모두 0인 벡터입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "# 훈련 레이블 벡터 변환\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "# 테스트 레이블 벡터 변환\n",
    "one_hot_test_labels = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 예제에서 이미 보았듯이 케라스에는 이를 위한 내장 함수가 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구성\n",
    "\n",
    "이 토픽 분류 문제는 이전의 영화 리뷰 분류 문제와 비슷해 보입니다. 두 경우 모두 짧은 텍스트를 분류하는 것이죠. 여기에서는 새로운 제약 사항이 추가되었습니다. 출력 클래스의 개수가 2에서 46개로 늘어난 점입니다. 출력 공간의 차원이 훨씬 커졌습니다.\n",
    "\n",
    "이전에 사용했던 것처럼 `Dense` 층을 쌓으면 각 층은 이전 층의 출력에서 제공한 정보만 사용할 수 있습니다. 한 층이 분류 문제에 필요한 일부 정보를 누락하면 그 다음 층에서 이를 복원할 방법이 없습니다. 각 층은 잠재적으로 정보의 병목이 될 수 있습니다. 이전 예제에서 16차원을 가진 중간층을 사용했지만 16차원 공간은 46개의 클래스를 구분하기에 너무 제약이 많을 것 같습니다. 이렇게 규모가 작은 층은 유용한 정보를 완전히 잃게 되는 정보의 병목 지점처럼 동작할 수 있습니다.\n",
    "\n",
    "이런 이유로 좀 더 규모가 큰 층을 사용하겠습니다. 64개의 유닛을 사용해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 구조에서 주목해야 할 점이 두 가지 있습니다:\n",
    "\n",
    "* 마지막 `Dense` 층의 크기가 46입니다. 각 입력 샘플에 대해서 46차원의 벡터를 출력한다는 뜻입니다. 이 벡터의 각 원소(각 차원)은 각기 다른 출력 클래스가 인코딩된 것입니다.\n",
    "* 마지막 층에 `softmax` 활성화 함수가 사용되었습니다. MNIST 예제에서 이런 방식을 보았습니다. 각 입력 샘플마다 46개의 출력 클래스에 대한 확률 분포를 출력합니다. 즉, 46차원의 출력 벡터를 만들며 `output[i]`는 어떤 샘플이 클래스 `i`에 속할 확률입니다. 46개의 값을 모두 더하면 1이 됩니다.\n",
    "\n",
    "이런 문제에 사용할 최선의 손실 함수는 `categorical_crossentropy`입니다. 이 함수는 두 확률 분포의 사이의 거리를 측정합니다. 여기에서는 네트워크가 출력한 확률 분포와 진짜 레이블의 분포 사이의 거리입니다. 두 분포 사이의 거리를 최소화하면 진짜 레이블에 가능한 가까운 출력을 내도록 모델을 훈련하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 검증\n",
    "\n",
    "훈련 데이터에서 1,000개의 샘플을 따로 떼어서 검증 세트로 사용하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 20번의 에포크로 모델을 훈련시킵니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 132us/step - loss: 2.4999 - accuracy: 0.5167 - val_loss: 1.6612 - val_accuracy: 0.6150\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 91us/step - loss: 1.4060 - accuracy: 0.6899 - val_loss: 1.2999 - val_accuracy: 0.6990\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 95us/step - loss: 1.0531 - accuracy: 0.7681 - val_loss: 1.1185 - val_accuracy: 0.7430\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 93us/step - loss: 0.8276 - accuracy: 0.8177 - val_loss: 1.0236 - val_accuracy: 0.7720\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 87us/step - loss: 0.6693 - accuracy: 0.8489 - val_loss: 0.9795 - val_accuracy: 0.7870\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 88us/step - loss: 0.5333 - accuracy: 0.8847 - val_loss: 0.9586 - val_accuracy: 0.7780\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 88us/step - loss: 0.4334 - accuracy: 0.9072 - val_loss: 0.8901 - val_accuracy: 0.8060\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 84us/step - loss: 0.3500 - accuracy: 0.9256 - val_loss: 0.9189 - val_accuracy: 0.8050\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 98us/step - loss: 0.2936 - accuracy: 0.9350 - val_loss: 0.8864 - val_accuracy: 0.8160\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 88us/step - loss: 0.2427 - accuracy: 0.9440 - val_loss: 0.9147 - val_accuracy: 0.8100\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 97us/step - loss: 0.2084 - accuracy: 0.9466 - val_loss: 0.9237 - val_accuracy: 0.8160\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 96us/step - loss: 0.1825 - accuracy: 0.9519 - val_loss: 0.9279 - val_accuracy: 0.8130\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 96us/step - loss: 0.1699 - accuracy: 0.9520 - val_loss: 0.9545 - val_accuracy: 0.8120\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 85us/step - loss: 0.1506 - accuracy: 0.9554 - val_loss: 0.9920 - val_accuracy: 0.7970\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 97us/step - loss: 0.1366 - accuracy: 0.9559 - val_loss: 1.0574 - val_accuracy: 0.7900\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 80us/step - loss: 0.1327 - accuracy: 0.9573 - val_loss: 1.0238 - val_accuracy: 0.8060\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 86us/step - loss: 0.1272 - accuracy: 0.9559 - val_loss: 1.0399 - val_accuracy: 0.7980\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 94us/step - loss: 0.1196 - accuracy: 0.9575 - val_loss: 1.0470 - val_accuracy: 0.8050\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 88us/step - loss: 0.1106 - accuracy: 0.9578 - val_loss: 1.1337 - val_accuracy: 0.7880\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 82us/step - loss: 0.1118 - accuracy: 0.9574 - val_loss: 1.1157 - val_accuracy: 0.7880\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손실과 정확도 곡선을 그려 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그래프를 초기화합니다\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 모델은 9번째 에포크 이후에 과대적합이 시작됩니다. 9번의 에포크로 새로운 모델을 훈련하고 테스트 세트에서 평가하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 1s 104us/step - loss: 2.6813 - accuracy: 0.5125 - val_loss: 1.7636 - val_accuracy: 0.6380\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 92us/step - loss: 1.4438 - accuracy: 0.6967 - val_loss: 1.3025 - val_accuracy: 0.7150\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 91us/step - loss: 1.0548 - accuracy: 0.7710 - val_loss: 1.1550 - val_accuracy: 0.7500\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 91us/step - loss: 0.8309 - accuracy: 0.8234 - val_loss: 1.0642 - val_accuracy: 0.7770\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 98us/step - loss: 0.6676 - accuracy: 0.8579 - val_loss: 0.9973 - val_accuracy: 0.8020\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 91us/step - loss: 0.5421 - accuracy: 0.8824 - val_loss: 0.9582 - val_accuracy: 0.8020\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 92us/step - loss: 0.4394 - accuracy: 0.9077 - val_loss: 0.9394 - val_accuracy: 0.8080\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 92us/step - loss: 0.3588 - accuracy: 0.9257 - val_loss: 0.9301 - val_accuracy: 0.8170\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 89us/step - loss: 0.3036 - accuracy: 0.9369 - val_loss: 0.9368 - val_accuracy: 0.8140\n",
      "2246/2246 [==============================] - 0s 65us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=9,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9890463156882716, 0.790739119052887]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대략 78%의 정확도를 달성했습니다. 균형 잡힌 이진 분류 문제에서 완전히 무작위로 분류하면 50%의 정확도를 달성합니다. 이 문제는 불균형한 데이터셋을 사용하므로 무작위로 분류하면 19% 정도를 달성합니다. 여기에 비하면 이 결과는 꽤 좋은 편입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19100623330365094"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "test_labels_copy = copy.copy(test_labels)\n",
    "np.random.shuffle(test_labels_copy)\n",
    "float(np.sum(np.array(test_labels) == np.array(test_labels_copy))) / len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 새로운 데이터에 대해 예측하기\n",
    "\n",
    "모델 인스턴스의 `predict` 메서드는 46개 토픽에 대한 확률 분포를 반환합니다. 테스트 데이터 전체에 대한 토픽을 예측해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`predictions`의 각 항목은 길이가 46인 벡터입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 벡터의 원소 합은 1입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000001"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 큰 값이 예측 클래스가 됩니다. 즉, 가장 확률이 높은 클래스입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 레이블과 손실을 다루는 다른 방법\n",
    "\n",
    "앞서 언급한 것처럼 레이블을 인코딩하는 다른 방법은 다음과 같이 정수 텐서로 변환하는 것입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 방식을 사용하려면 손실 함수 하나만 바꾸면 됩니다. 코드 3-21에 사용된 손실 함수 `categorical_crossentropy`는 레이블이 범주형 인코딩되어 있을 것이라고 기대합니다. 정수 레이블을 사용할 때는 `sparse_categorical_crossentropy`를 사용해야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 손실 함수는 인터페이스만 다를 뿐이고 수학적으로는 `categorical_crossentropy`와 동일합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 충분히 큰 중간층을 두어야 하는 이유\n",
    "\n",
    "앞서 언급한 것처럼 마지막 출력이 46차원이기 때문에 중간층의 히든 유닛이 46개보다 많이 적어서는 안 됩니다. 46차원보다 훨씬 작은 중간층(예를 들면 4차원)을 두면 정보의 병목이 어떻게 나타나는지 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 117us/step - loss: 3.0558 - accuracy: 0.2067 - val_loss: 2.3034 - val_accuracy: 0.5790\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 105us/step - loss: 1.7524 - accuracy: 0.6196 - val_loss: 1.5195 - val_accuracy: 0.6200\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 102us/step - loss: 1.3026 - accuracy: 0.6824 - val_loss: 1.3684 - val_accuracy: 0.6660\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 102us/step - loss: 1.1261 - accuracy: 0.7239 - val_loss: 1.3115 - val_accuracy: 0.7000\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 108us/step - loss: 1.0062 - accuracy: 0.7531 - val_loss: 1.2923 - val_accuracy: 0.7110\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 98us/step - loss: 0.9098 - accuracy: 0.7680 - val_loss: 1.2709 - val_accuracy: 0.7130\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 101us/step - loss: 0.8306 - accuracy: 0.7840 - val_loss: 1.2759 - val_accuracy: 0.7140\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 101us/step - loss: 0.7644 - accuracy: 0.7937 - val_loss: 1.3361 - val_accuracy: 0.7140\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 98us/step - loss: 0.7086 - accuracy: 0.8061 - val_loss: 1.3299 - val_accuracy: 0.7250\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 102us/step - loss: 0.6602 - accuracy: 0.8131 - val_loss: 1.3841 - val_accuracy: 0.7180\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 99us/step - loss: 0.6187 - accuracy: 0.8165 - val_loss: 1.4246 - val_accuracy: 0.7130\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 102us/step - loss: 0.5825 - accuracy: 0.8220 - val_loss: 1.4513 - val_accuracy: 0.7180\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 99us/step - loss: 0.5479 - accuracy: 0.8368 - val_loss: 1.5031 - val_accuracy: 0.7120\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 99us/step - loss: 0.5199 - accuracy: 0.8484 - val_loss: 1.5668 - val_accuracy: 0.7210\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 100us/step - loss: 0.4911 - accuracy: 0.8553 - val_loss: 1.6077 - val_accuracy: 0.7170\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 104us/step - loss: 0.4676 - accuracy: 0.8671 - val_loss: 1.6534 - val_accuracy: 0.7140\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 103us/step - loss: 0.4463 - accuracy: 0.8747 - val_loss: 1.6758 - val_accuracy: 0.7110\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 102us/step - loss: 0.4240 - accuracy: 0.8809 - val_loss: 1.7394 - val_accuracy: 0.7180\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 97us/step - loss: 0.4083 - accuracy: 0.8830 - val_loss: 1.7532 - val_accuracy: 0.7190\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 96us/step - loss: 0.3896 - accuracy: 0.8851 - val_loss: 1.8681 - val_accuracy: 0.7150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f5491609ba8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 정확도의 최고 값은 약 71%로 8% 정도 감소되었습니다. 이런 손실의 대부분 원인은 많은 정보(46개 클래스의 분할 초평면을 복원하기에 충분한 정보)를 중간층의 저차원 표현 공간으로 압축하려고 했기 때문입니다. 이 네트워크는 필요한 정보 대부분을 4차원 표현 안에 구겨 넣었지만 전부는 넣지 못했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추가 실험\n",
    "\n",
    "* 더 크거나 작은 층을 사용해 보세요: 32개 유닛, 128개 유닛 등\n",
    "* 여기에서 두 개의 은닉층을 사용했습니다. 한 개의 은닉층이나 세 개의 은닉층을 사용해 보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "다음은 이 예제에서 배운 것들입니다.\n",
    "\n",
    "* N개의 클래스로 데이터 포인트를 분류하려면 네트워크의 마지막 `Dense` 층의 크기는 N이어야 합니다.\n",
    "* 단일 레이블, 다중 분류 문제에서는 N개의 클래스에 대한 확률 분포를 출력하기 위해 `softmax` 활성화 함수를 사용해야 합니다.\n",
    "* 이런 문제에는 항상 범주형 크로스엔트로피를 사용해야 합니다. 이 함수는 모델이 출력한 확률 분포와 타깃 분포 사이의 거리를 최소화합니다.\n",
    "* 다중 분류에서 레이블을 다루는 두 가지 방법이 있습니다.\n",
    "    * 레이블을 범주형 인코딩(또는 원-핫 인코딩)으로 인코딩하고 `categorical_crossentropy` 손실 함수를 사용합니다.\n",
    "    * 레이블을 정수로 인코딩하고 `sparse_categorical_crossentropy` 손실 함수를 사용합니다.\n",
    "* 많은 수의 범주를 분류할 때 중간층의 크기가 너무 작아 네트워크에 정보의 병목이 생기지 않도록 해야 합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
