{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 상의 편의를 위한 Initial Setting\n",
    "\n",
    "# 실행결과를 한 창에 표시\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# numpy 소숫점 setting\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=7)\n",
    "\n",
    "# pandas이용하여 grid display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)         # 최대 표시 줄 수 제한 해제\n",
    "pd.set_option('display.max_columns', None)  # 최대 표시 컬럼 수 제한 해제\n",
    "pd.set_option('display.max_colwidth', -1)        # 컬럼내 데이터 표시 제한 해제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Iris 품종 (Versicolor, Virginica, Setosa)\n",
    "![iris(1)](https://user-images.githubusercontent.com/38086434/67282294-6423ef00-f50c-11e9-945d-42ce959a0cce.jpg)\n",
    "\n",
    " ### Iris Petal(꽃잎) width / length 에 따른 Categorize\n",
    "![iris(2)](https://user-images.githubusercontent.com/38086434/67282497-e0b6cd80-f50c-11e9-97a3-0402ab5f1ecc.jpg)\n",
    "\n",
    " #### 출처 : http://articles.concreteinteractive.com/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image\n",
    "# Image(\"./image/iris(1).jpg\")\n",
    "# Image(\"./image/iris(2).jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런의  load_iris method를 import 하여 iris data, label을 얻음\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_label = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런 의  train_test_split method를 import 하여 train_data : test_data = 6:4 의 비율로 split 함\n",
    "from sklearn.model_selection import train_test_split\n",
    "(train_data, test_data, train_label, test_label) = train_test_split(iris_data, iris_label, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(90, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(90,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 iris data의 shape을 확인 (150건의 row가 존재하고, 각 row에는  다음과 같이 붓꽃의 꽃잎과 꽃받침의  length, width 임\n",
    "# iris_data shape : (150 , 4)      --> 전체 150 건의 Data,  [‘sepal length (cm)’, ‘sepal width (cm)’, ‘petal length (cm)’, ‘petal width (cm)’] 로 구성\n",
    "# train_data shape : (90 , 4)     --> 전체의 60%인 90 row의 Data, [‘sepal length (cm)’, ‘sepal width (cm)’, ‘petal length (cm)’, ‘petal width (cm)’] 로 구성\n",
    "# test_data shape : (60 , 4)       --> 전체의 40%인 60 row의 Data, [‘sepal length (cm)’, ‘sepal width (cm)’, ‘petal length (cm)’, ‘petal width (cm)’] 로 구성\n",
    "# train_label shape : (90,)         --> 전체의 60%인 90 row의 Data, 각 Data는 0, 1, 2 중 하나로 구성 (0:Setosa, 1:Versicolor, 2:Virginica)\n",
    "# test_label shape : (60,)           --> 전체의 40%인 60 row의 Data, 각 Data는 0, 1, 2 중 하나로 구성 (0:Setosa, 1:Versicolor, 2:Virginica)\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#  Train/Test Data : [‘sepal length (cm)’, ‘sepal width (cm)’, ‘petal length (cm)’, ‘petal width (cm)’]    * sepal: 꽃받침 / petal: 꽃잎\n",
    "#  Train/Test Label :   0: Setosa\n",
    "#                                   1: Versicolor\n",
    "#                                   2: Virginica\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "iris_data.shape\n",
    "train_data.shape\n",
    "test_data.shape\n",
    "train_label.shape\n",
    "test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Network에 주입하기 위해 train_label, test_label을 one-hot-encoding 형식으로 변환\n",
    "from keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_label)\n",
    "test_labels = to_categorical(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras를 import 하고, 계층을 선형적으로 쌓는 sequential 모델을 사용\n",
    "# add method를 이용하여 쉽게 layer를 쌓을 수 있음\n",
    "# 활성화 함수는 relu를 사용하고, input shape는 4개의 iris sepal/petal의 length/width 임 \n",
    "# 즉, [‘sepal length (cm)’, ‘sepal width (cm)’, ‘petal length (cm)’, ‘petal width (cm)’]    * sepal: 꽃받침 / petal: 꽃잎)\n",
    "# 출력함수로 softmax 함수를 이용, 4개의 입력 값을 0~1 사이의 값으로 정규화 하고, argmax method를 이용하여 one-hot encoding\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(64, activation='relu', input_shape=(4,)))\n",
    "# 입력층 : 입력 parameter는 4이고, 출력 parameter는 64 임, 활성화 함수는 relu\n",
    "# 즉 [‘sepal length (cm)’, ‘sepal width (cm)’, ‘petal length (cm)’, ‘petal width (cm)’]\n",
    "\n",
    "network.add(layers.Dense(64, activation='relu'))\n",
    "# 은닉층 : 입력 parameter는 64(이전 layer의 출력)이고, 출력 parameter는 64 임, 활성화 함수는 relu\n",
    "\n",
    "network.add(layers.Dense(3, activation='softmax'))\n",
    "# 출력층 : 입력 parameter는 64(이전 layer의 출력) 이고, 출력 parameter는 3임, 활성화 함수는 softmax\n",
    "# 즉  0: Setosa, 1: Versicolor, 2: Virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                320       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 4,675\n",
      "Trainable params: 4,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network.summary()\n",
    "\n",
    "#  dense_1 layer의 전체 paramenter의 수는 64 * 4 + 64 = 320 임 (추가적으로 더하는 64는 bias)\n",
    "#  dense_2 layer의 전체 paramenter의 수는 64 * 64 + 64 = 4,160 임 (추가적으로 더하는 64은 bias)\n",
    "#  dense_3 layer의 전체 paramenter의 수는 64 * 3 + 3 = 195 임 (추가적으로 더하는 3은 bias)\n",
    "# 그러므로 총 paramter의 수는 320 + 4,160 + 195 = 4,675"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile method를 이용하여 학습 과정을 구성\n",
    "# 옵티마이저는 Adam을사용하고, 손실함수는 교차 엔트로피 오차(Cross Entropy Error) 함수를 이용\n",
    "\n",
    "network.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "90/90 [==============================] - 0s 56us/step - loss: 0.1482 - accuracy: 0.9778\n",
      "Epoch 2/40\n",
      "90/90 [==============================] - 0s 49us/step - loss: 0.1439 - accuracy: 0.9667\n",
      "Epoch 3/40\n",
      "90/90 [==============================] - 0s 47us/step - loss: 0.1378 - accuracy: 0.9778\n",
      "Epoch 4/40\n",
      "90/90 [==============================] - 0s 45us/step - loss: 0.1347 - accuracy: 0.9778\n",
      "Epoch 5/40\n",
      "90/90 [==============================] - 0s 50us/step - loss: 0.1311 - accuracy: 0.9778\n",
      "Epoch 6/40\n",
      "90/90 [==============================] - 0s 44us/step - loss: 0.1272 - accuracy: 0.9778\n",
      "Epoch 7/40\n",
      "90/90 [==============================] - 0s 44us/step - loss: 0.1327 - accuracy: 0.9667\n",
      "Epoch 8/40\n",
      "90/90 [==============================] - 0s 51us/step - loss: 0.1173 - accuracy: 0.9778\n",
      "Epoch 9/40\n",
      "90/90 [==============================] - 0s 46us/step - loss: 0.1233 - accuracy: 0.9667\n",
      "Epoch 10/40\n",
      "90/90 [==============================] - 0s 44us/step - loss: 0.1240 - accuracy: 0.9667\n",
      "Epoch 11/40\n",
      "90/90 [==============================] - 0s 44us/step - loss: 0.1205 - accuracy: 0.9778\n",
      "Epoch 12/40\n",
      "90/90 [==============================] - 0s 47us/step - loss: 0.1208 - accuracy: 0.9667\n",
      "Epoch 13/40\n",
      "90/90 [==============================] - 0s 47us/step - loss: 0.1183 - accuracy: 0.9667\n",
      "Epoch 14/40\n",
      "90/90 [==============================] - 0s 48us/step - loss: 0.1220 - accuracy: 0.9667\n",
      "Epoch 15/40\n",
      "90/90 [==============================] - 0s 45us/step - loss: 0.1079 - accuracy: 0.9667\n",
      "Epoch 16/40\n",
      "90/90 [==============================] - 0s 47us/step - loss: 0.1125 - accuracy: 0.9667\n",
      "Epoch 17/40\n",
      "90/90 [==============================] - 0s 46us/step - loss: 0.1081 - accuracy: 0.9667\n",
      "Epoch 18/40\n",
      "90/90 [==============================] - 0s 45us/step - loss: 0.1019 - accuracy: 0.9889\n",
      "Epoch 19/40\n",
      "90/90 [==============================] - 0s 44us/step - loss: 0.1010 - accuracy: 0.9778\n",
      "Epoch 20/40\n",
      "90/90 [==============================] - 0s 43us/step - loss: 0.0977 - accuracy: 0.9778\n",
      "Epoch 21/40\n",
      "90/90 [==============================] - 0s 44us/step - loss: 0.0999 - accuracy: 0.9778\n",
      "Epoch 22/40\n",
      "90/90 [==============================] - 0s 49us/step - loss: 0.0962 - accuracy: 0.9778\n",
      "Epoch 23/40\n",
      "90/90 [==============================] - 0s 48us/step - loss: 0.0945 - accuracy: 0.9889\n",
      "Epoch 24/40\n",
      "90/90 [==============================] - 0s 48us/step - loss: 0.0938 - accuracy: 0.9889\n",
      "Epoch 25/40\n",
      "90/90 [==============================] - 0s 46us/step - loss: 0.0986 - accuracy: 0.9778\n",
      "Epoch 26/40\n",
      "90/90 [==============================] - 0s 45us/step - loss: 0.0962 - accuracy: 0.9778\n",
      "Epoch 27/40\n",
      "90/90 [==============================] - 0s 46us/step - loss: 0.0912 - accuracy: 0.9778\n",
      "Epoch 28/40\n",
      "90/90 [==============================] - 0s 49us/step - loss: 0.0893 - accuracy: 0.9889\n",
      "Epoch 29/40\n",
      "90/90 [==============================] - 0s 51us/step - loss: 0.0887 - accuracy: 0.9778\n",
      "Epoch 30/40\n",
      "90/90 [==============================] - 0s 52us/step - loss: 0.0897 - accuracy: 0.9778\n",
      "Epoch 31/40\n",
      "90/90 [==============================] - 0s 47us/step - loss: 0.0868 - accuracy: 0.9778\n",
      "Epoch 32/40\n",
      "90/90 [==============================] - 0s 47us/step - loss: 0.0859 - accuracy: 0.9889\n",
      "Epoch 33/40\n",
      "90/90 [==============================] - 0s 46us/step - loss: 0.0857 - accuracy: 0.9889\n",
      "Epoch 34/40\n",
      "90/90 [==============================] - 0s 43us/step - loss: 0.0853 - accuracy: 0.9889\n",
      "Epoch 35/40\n",
      "90/90 [==============================] - 0s 45us/step - loss: 0.0840 - accuracy: 0.9778\n",
      "Epoch 36/40\n",
      "90/90 [==============================] - 0s 45us/step - loss: 0.0850 - accuracy: 0.9889\n",
      "Epoch 37/40\n",
      "90/90 [==============================] - 0s 48us/step - loss: 0.0833 - accuracy: 0.9778\n",
      "Epoch 38/40\n",
      "90/90 [==============================] - 0s 50us/step - loss: 0.0833 - accuracy: 0.9778\n",
      "Epoch 39/40\n",
      "90/90 [==============================] - 0s 48us/step - loss: 0.0842 - accuracy: 0.9778\n",
      "Epoch 40/40\n",
      "90/90 [==============================] - 0s 49us/step - loss: 0.0801 - accuracy: 0.9889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f03292f3c50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit method를 이용해서 정해진 epoch 만큼  Training을 수행\n",
    "# 이때 위에서 재 정의한 train_data, train_label을 주입하고, epoch를 지정\n",
    "\n",
    "network.fit(train_data, train_labels, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 77us/step\n"
     ]
    }
   ],
   "source": [
    "# evaluate method를 이용하여 입력 test data에 대한 loss, accuracy를 계산\n",
    "test_loss, test_acc = network.evaluate(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc :  0.9833333492279053\n",
      "test_loss :  0.08893469125032424\n"
     ]
    }
   ],
   "source": [
    "print('test_acc : ', test_acc)\n",
    "print('test_loss : ', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = train_data[:80]\n",
    "partial_x_train = train_data[80:]\n",
    "\n",
    "y_val = train_labels[:80]\n",
    "partial_y_train = train_labels[80:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90 samples, validate on 80 samples\n",
      "Epoch 1/40\n",
      "90/90 [==============================] - 0s 38us/step - loss: 0.0820 - accuracy: 0.9667 - val_loss: 0.0627 - val_accuracy: 0.9750\n",
      "Epoch 2/40\n",
      "90/90 [==============================] - 0s 31us/step - loss: 0.0825 - accuracy: 0.9667 - val_loss: 0.0624 - val_accuracy: 0.9750\n",
      "Epoch 3/40\n",
      "90/90 [==============================] - 0s 33us/step - loss: 0.0821 - accuracy: 0.9667 - val_loss: 0.0620 - val_accuracy: 0.9875\n",
      "Epoch 4/40\n",
      "90/90 [==============================] - 0s 31us/step - loss: 0.0809 - accuracy: 0.9778 - val_loss: 0.0620 - val_accuracy: 0.9875\n",
      "Epoch 5/40\n",
      "90/90 [==============================] - 0s 30us/step - loss: 0.0797 - accuracy: 0.9778 - val_loss: 0.0627 - val_accuracy: 1.0000\n",
      "Epoch 6/40\n",
      "90/90 [==============================] - 0s 30us/step - loss: 0.0790 - accuracy: 0.9889 - val_loss: 0.0640 - val_accuracy: 1.0000\n",
      "Epoch 7/40\n",
      "90/90 [==============================] - 0s 28us/step - loss: 0.0789 - accuracy: 0.9889 - val_loss: 0.0655 - val_accuracy: 0.9875\n",
      "Epoch 8/40\n",
      "90/90 [==============================] - 0s 29us/step - loss: 0.0793 - accuracy: 0.9778 - val_loss: 0.0663 - val_accuracy: 0.9875\n",
      "Epoch 9/40\n",
      "90/90 [==============================] - 0s 32us/step - loss: 0.0796 - accuracy: 0.9778 - val_loss: 0.0660 - val_accuracy: 0.9875\n",
      "Epoch 10/40\n",
      "90/90 [==============================] - 0s 31us/step - loss: 0.0794 - accuracy: 0.9778 - val_loss: 0.0648 - val_accuracy: 0.9875\n",
      "Epoch 11/40\n",
      "90/90 [==============================] - 0s 31us/step - loss: 0.0788 - accuracy: 0.9778 - val_loss: 0.0632 - val_accuracy: 1.0000\n",
      "Epoch 12/40\n",
      "90/90 [==============================] - 0s 31us/step - loss: 0.0781 - accuracy: 0.9889 - val_loss: 0.0617 - val_accuracy: 1.0000\n",
      "Epoch 13/40\n",
      "90/90 [==============================] - 0s 31us/step - loss: 0.0777 - accuracy: 0.9889 - val_loss: 0.0607 - val_accuracy: 1.0000\n",
      "Epoch 14/40\n",
      "90/90 [==============================] - 0s 30us/step - loss: 0.0776 - accuracy: 0.9889 - val_loss: 0.0600 - val_accuracy: 1.0000\n",
      "Epoch 15/40\n",
      "90/90 [==============================] - 0s 29us/step - loss: 0.0776 - accuracy: 0.9889 - val_loss: 0.0597 - val_accuracy: 0.9875\n",
      "Epoch 16/40\n",
      "90/90 [==============================] - 0s 29us/step - loss: 0.0777 - accuracy: 0.9778 - val_loss: 0.0594 - val_accuracy: 0.9875\n",
      "Epoch 17/40\n",
      "90/90 [==============================] - 0s 31us/step - loss: 0.0775 - accuracy: 0.9778 - val_loss: 0.0594 - val_accuracy: 0.9875\n",
      "Epoch 18/40\n",
      "90/90 [==============================] - 0s 29us/step - loss: 0.0772 - accuracy: 0.9778 - val_loss: 0.0595 - val_accuracy: 1.0000\n",
      "Epoch 19/40\n",
      "90/90 [==============================] - 0s 31us/step - loss: 0.0767 - accuracy: 0.9889 - val_loss: 0.0598 - val_accuracy: 1.0000\n",
      "Epoch 20/40\n",
      "90/90 [==============================] - 0s 29us/step - loss: 0.0764 - accuracy: 0.9889 - val_loss: 0.0602 - val_accuracy: 1.0000\n",
      "Epoch 21/40\n",
      "90/90 [==============================] - 0s 30us/step - loss: 0.0763 - accuracy: 0.9889 - val_loss: 0.0607 - val_accuracy: 1.0000\n",
      "Epoch 22/40\n",
      "90/90 [==============================] - 0s 29us/step - loss: 0.0762 - accuracy: 0.9889 - val_loss: 0.0609 - val_accuracy: 1.0000\n",
      "Epoch 23/40\n",
      "90/90 [==============================] - 0s 29us/step - loss: 0.0761 - accuracy: 0.9889 - val_loss: 0.0607 - val_accuracy: 1.0000\n",
      "Epoch 24/40\n",
      "90/90 [==============================] - 0s 30us/step - loss: 0.0760 - accuracy: 0.9889 - val_loss: 0.0603 - val_accuracy: 1.0000\n",
      "Epoch 25/40\n",
      "90/90 [==============================] - 0s 29us/step - loss: 0.0758 - accuracy: 0.9889 - val_loss: 0.0596 - val_accuracy: 1.0000\n",
      "Epoch 26/40\n",
      "90/90 [==============================] - 0s 29us/step - loss: 0.0755 - accuracy: 0.9889 - val_loss: 0.0589 - val_accuracy: 1.0000\n",
      "Epoch 27/40\n",
      "90/90 [==============================] - 0s 30us/step - loss: 0.0752 - accuracy: 0.9889 - val_loss: 0.0582 - val_accuracy: 1.0000\n",
      "Epoch 28/40\n",
      "90/90 [==============================] - 0s 29us/step - loss: 0.0751 - accuracy: 0.9889 - val_loss: 0.0577 - val_accuracy: 1.0000\n",
      "Epoch 29/40\n",
      "90/90 [==============================] - 0s 29us/step - loss: 0.0750 - accuracy: 0.9889 - val_loss: 0.0574 - val_accuracy: 1.0000\n",
      "Epoch 30/40\n",
      "90/90 [==============================] - 0s 30us/step - loss: 0.0748 - accuracy: 0.9889 - val_loss: 0.0572 - val_accuracy: 1.0000\n",
      "Epoch 31/40\n",
      "90/90 [==============================] - 0s 30us/step - loss: 0.0747 - accuracy: 0.9889 - val_loss: 0.0571 - val_accuracy: 1.0000\n",
      "Epoch 32/40\n",
      "90/90 [==============================] - 0s 28us/step - loss: 0.0745 - accuracy: 0.9889 - val_loss: 0.0571 - val_accuracy: 1.0000\n",
      "Epoch 33/40\n",
      "90/90 [==============================] - 0s 33us/step - loss: 0.0743 - accuracy: 0.9889 - val_loss: 0.0572 - val_accuracy: 1.0000\n",
      "Epoch 34/40\n",
      "90/90 [==============================] - 0s 30us/step - loss: 0.0741 - accuracy: 0.9889 - val_loss: 0.0573 - val_accuracy: 1.0000\n",
      "Epoch 35/40\n",
      "90/90 [==============================] - 0s 30us/step - loss: 0.0740 - accuracy: 0.9889 - val_loss: 0.0573 - val_accuracy: 1.0000\n",
      "Epoch 36/40\n",
      "90/90 [==============================] - 0s 29us/step - loss: 0.0738 - accuracy: 0.9889 - val_loss: 0.0572 - val_accuracy: 1.0000\n",
      "Epoch 37/40\n",
      "90/90 [==============================] - 0s 31us/step - loss: 0.0737 - accuracy: 0.9889 - val_loss: 0.0571 - val_accuracy: 1.0000\n",
      "Epoch 38/40\n",
      "90/90 [==============================] - 0s 31us/step - loss: 0.0735 - accuracy: 0.9889 - val_loss: 0.0568 - val_accuracy: 1.0000\n",
      "Epoch 39/40\n",
      "90/90 [==============================] - 0s 31us/step - loss: 0.0734 - accuracy: 0.9889 - val_loss: 0.0565 - val_accuracy: 1.0000\n",
      "Epoch 40/40\n",
      "90/90 [==============================] - 0s 29us/step - loss: 0.0732 - accuracy: 0.9889 - val_loss: 0.0562 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = network.fit(train_data, train_labels, epochs=40, batch_size = 256, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0328394e48>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f03283e7128>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training and validation loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epochs')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f0328374a58>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# ‘bo’는 파란색 점을 의미합니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# ‘b’는 파란색 실선을 의미합니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
